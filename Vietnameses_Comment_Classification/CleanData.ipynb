{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CleanData.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1egXGq1E6n7jpc1Jforkel9rKh2bQrObY","authorship_tag":"ABX9TyOIIkrL67MsP+vOQdMxc0fN"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_0WwROPHmxmP","executionInfo":{"status":"ok","timestamp":1611545794643,"user_tz":-420,"elapsed":117309,"user":{"displayName":"DUNG VAN","photoUrl":"","userId":"12643198790555521098"}},"outputId":"93fe443f-40c9-4b88-b526-2178f47a1ee9"},"source":["!pip install underthesea"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting underthesea\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/5f/03ab9091b88e7851aa92da33f8eea6f111423cc1194cf1636c63c1fff3d0/underthesea-1.3.1-py3-none-any.whl (7.5MB)\n","\u001b[K     |████████████████████████████████| 7.5MB 6.4MB/s \n","\u001b[?25hCollecting unidecode\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/65/91eab655041e9e92f948cb7302e54962035762ce7b518272ed9d6b269e93/Unidecode-1.1.2-py2.py3-none-any.whl (239kB)\n","\u001b[K     |████████████████████████████████| 245kB 47.6MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from underthesea) (3.13)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from underthesea) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from underthesea) (4.41.1)\n","Collecting python-crfsuite>=0.9.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n","\u001b[K     |████████████████████████████████| 747kB 38.9MB/s \n","\u001b[?25hRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from underthesea) (7.1.2)\n","Collecting transformers<=3.5.1,>=3.5.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 54.2MB/s \n","\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from underthesea) (1.0.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from underthesea) (0.22.2.post1)\n","Collecting seqeval\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.4MB/s \n","\u001b[?25hCollecting torch<=1.5.1,>=1.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/01/457b49d790b6c4b9720e6f9dbbb617692f6ce8afdaadf425c055c41a7416/torch-1.5.1-cp36-cp36m-manylinux1_x86_64.whl (753.2MB)\n","\u001b[K     |████████████████████████████████| 753.2MB 22kB/s \n","\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from underthesea) (3.2.5)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->underthesea) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->underthesea) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->underthesea) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->underthesea) (3.0.4)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 52.9MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (1.19.5)\n","Collecting sentencepiece==0.1.91\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 41.4MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (3.12.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (20.8)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (3.0.12)\n","Collecting tokenizers==0.9.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 40.9MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (0.8)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->underthesea) (1.4.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<=1.5.1,>=1.1.0->underthesea) (0.16.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->underthesea) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers<=3.5.1,>=3.5.0->underthesea) (51.3.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<=3.5.1,>=3.5.0->underthesea) (2.4.7)\n","Building wheels for collected packages: seqeval, sacremoses\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-cp36-none-any.whl size=16171 sha256=c0250cd4eb4b6faae21c32fb0993889a1ff791f6ea68bfc527fefe5966fe1736\n","  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=79a14e857f40f6b07b6c3a3f85d8400ebe41a623e665d22a34b52a9ba5f38ea5\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built seqeval sacremoses\n","\u001b[31mERROR: torchvision 0.8.1+cu101 has requirement torch==1.7.0, but you'll have torch 1.5.1 which is incompatible.\u001b[0m\n","Installing collected packages: unidecode, python-crfsuite, sacremoses, sentencepiece, tokenizers, transformers, seqeval, torch, underthesea\n","  Found existing installation: torch 1.7.0+cu101\n","    Uninstalling torch-1.7.0+cu101:\n","      Successfully uninstalled torch-1.7.0+cu101\n","Successfully installed python-crfsuite-0.9.7 sacremoses-0.0.43 sentencepiece-0.1.91 seqeval-1.2.2 tokenizers-0.9.3 torch-1.5.1 transformers-3.5.1 underthesea-1.3.1 unidecode-1.1.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YFseZSxxgzfo"},"source":["correct_mapping = {\r\n","    \"ship\": \"vận chuyển\",\r\n","    \"shop\": \"cửa hàng\",\r\n","    \"m\": \"mình\",\r\n","    \"dc\":\"được\",\r\n","    \"mik\": \"mình\",\r\n","    \"ko\": \"không\",\r\n","    \"k\": \" không \",\r\n","    \"kh\": \"không\",\r\n","    \"khong\": \"không\",\r\n","    \"kg\": \"không\",\r\n","    \"khg\": \"không\",\r\n","    \"tl\": \"trả lời\",\r\n","    \"r\": \"rồi\",\r\n","    \"fb\": \"mạng xã hội\", # facebook\r\n","    \"face\": \"mạng xã hội\",\r\n","    \"thanks\": \"cảm ơn\",\r\n","    \"thank\": \"cảm ơn\",\r\n","    \"tks\": \"cảm ơn\",\r\n","    \"tk\": \"cảm ơn\",\r\n","    \"ok\": \"tốt\",\r\n","    \"dc\": \"được\",\r\n","    \"vs\": \"với\",\r\n","    \"đt\": \"điện thoại\",\r\n","    \"thjk\": \"thích\",\r\n","    \"qá\": \"quá\",\r\n","    \"trể\": \"trễ\",\r\n","    \"bgjo\": \"bao giờ\",\r\n","    \"sp\":\"sản phẩm\"\r\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"obirs_LJqXze"},"source":["train_path = '/content/drive/MyDrive/Comment Classification/data/train.crash'\r\n","train_csv = '/content/drive/MyDrive/Comment Classification/data/cleaned_train.csv'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ztbAlY8O3xI"},"source":["from keras.preprocessing.text import Tokenizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OMEylO3Lh-xM"},"source":["def tokmap(tok):\r\n","    if tok.lower() in correct_mapping:\r\n","        return correct_mapping[tok.lower()]\r\n","    else:\r\n","        return tok\r\n","\r\n","def preprocess(review):\r\n","    tokens = review.split()\r\n","    tokens = map(tokmap, tokens)\r\n","    return \" \".join(tokens)\r\n","\r\n","\r\n","def load_data(filepath, is_train=True):\r\n","    regex = 'train_'\r\n","    if not is_train:\r\n","        regex = 'test_'\r\n","\r\n","    a = []\r\n","    b = []\r\n","\r\n","    with open(filepath, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\r\n","        for line in f:\r\n","            line = line.strip()\r\n","            if regex in line:\r\n","                b.append(a)\r\n","                a = [line]\r\n","            elif line != \"\":\r\n","                a.append(line)\r\n","        b.append(a)\r\n","\r\n","    b = b[1:]\r\n","    lst = []\r\n","    for tp in b:\r\n","        idx = tp[0]\r\n","        if is_train:\r\n","            lb = int(tp.pop(-1))\r\n","        else:\r\n","            lb = \"0\"\r\n","        review = \" \".join(tp[1:])\r\n","        review = re.sub(r\"^\\\"*\", \"\", review)\r\n","        review = re.sub(r\"\\\"*$\", \"\", review)\r\n","        review_ = preprocess(review)\r\n","        review_ = re.sub(r'[^a-zA-Z0-9|á|ã|ạ|ả|à|í|ĩ|ị|ỉ|ì|é|è|ẽ|ẹ|ẻ|ó|ò|õ|ọ|ỏ|ú|ù|ủ|ũ|ụ|â|ấ|ầ|ẩ|ậ|ẫ|ă|ắ|ằ|ặ|ẵ|ẳ|ê|ế|ề|ễ|ệ|ể|ư|ứ|ừ|ữ|ự|ử|ô|ố|ồ|ỗ|ộ|ổ|ơ|ớ|ờ|ở|ỡ|ợ|ý|ỳ|ỷ|ỵ|ỹ|đ|Á|À|Ã|Ạ|Ả|Í|Ì|Ĩ|Ị|Ỉ|É|È|Ẽ|Ẹ|Ẻ|Ó|Ò|Õ|Ọ|Ỏ|Ú|Ù|Ủ|Ũ|Ụ|Â|Ấ|Ầ|Ẩ|Ẫ|Ậ|Ă|Ắ|Ằ|Ặ|Ẵ|Ẳ|Ê|Ế|Ề|Ễ|Ệ|Ể|Ư|Ứ|Ừ|Ữ|Ự|Ử|Ô|Ố|Ồ|Ỗ|Ổ|Ộ|Ơ|Ớ|Ờ|Ở|Ỡ|Ợ|Đ| ]',r'',review_)\r\n","        review_ws = word_tokenize(review_, format=\"text\")\r\n","        lst.append([idx, review, review_ws, lb])\r\n","    return lst\r\n","\r\n","def load_csv_data(filepath, textcol=\"text_ws\"):\r\n","    df = pd.read_csv(filepath)\r\n","    samples = [ str(text) for text in df[textcol] ]\r\n","    labels  = [ int(intent) for intent in df[\"label\"]]\r\n","    return samples, labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DVP93iULqiXY"},"source":["train_data = load_data(train_path)\r\n","test_data = load_data(test_path, is_train=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uBiLI6P2s9sW"},"source":["import pandas as pd\r\n","import csv"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QWZ-7VXEq18O"},"source":["cols = [\"id\", \"text\", \"text_ws\", \"label\"]\r\n","df_train = pd.DataFrame(data=train_data, columns=cols)\r\n","df_train.to_csv(train_csv, index=False, quoting=csv.QUOTE_NONNUMERIC)"],"execution_count":null,"outputs":[]}]}